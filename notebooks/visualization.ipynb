{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data_processing import load_features\n",
    "from src.models import load_model\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try custom-extracted first, then pre-extracted\n",
    "try:\n",
    "    features_path = \"../data/processed/features.csv\"\n",
    "    X, y = load_features(features_path)\n",
    "except FileNotFoundError:\n",
    "    features_path = \"../data/raw/Data/features_30_sec.csv\"\n",
    "    X, y = load_features(features_path)\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "\n",
    "# Show genre distribution\n",
    "print(\"\\nGenre distribution:\")\n",
    "genre_counts = y.value_counts()\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Feature statistics\n",
    "    print(\"Feature Statistics:\")\n",
    "    print(X.describe())\n",
    "    \n",
    "    # Correlation matrix for key features\n",
    "    key_features = ['tempo', 'spectral_centroid_mean', 'spectral_rolloff_mean', 'zero_crossing_rate_mean', 'rms_mean']\n",
    "    \n",
    "    available_features = [f for f in key_features if f in X.columns]\n",
    "    \n",
    "    if available_features:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        correlation_matrix = X[available_features].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Genre distribution plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    genre_counts.plot(kind='bar')\n",
    "    plt.title('Genre Distribution')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(genre_counts.values, labels=genre_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Genre Distribution (Pie Chart)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze tempo by genre\n",
    "    label_col = 'label' if 'label' in df.columns else 'genre'\n",
    "    if 'tempo' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        df.boxplot(column='tempo', by=label_col, ax=plt.gca())\n",
    "        plt.title('Tempo by Genre')\n",
    "        plt.suptitle('')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        if 'spectral_centroid_mean' in df.columns:\n",
    "            df.boxplot(column='spectral_centroid_mean', by=label_col, ax=plt.gca())\n",
    "            plt.title('Spectral Centroid by Genre')\n",
    "            plt.suptitle('')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model_path = \"../models/random_forest_model.pkl\"\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    print(f\"Model type: {model.model_name}\")\n",
    "    \n",
    "    # Example prediction (using a sample from the data)\n",
    "    if df is not None:\n",
    "        sample_features = X.iloc[0:1].values\n",
    "        \n",
    "        # Scale features using the model's scaler\n",
    "        sample_features_scaled = model.scaler.transform(sample_features)\n",
    "        \n",
    "        # Make prediction\n",
    "        y_pred_num = model.model.predict(sample_features_scaled)\n",
    "        prediction = model.label_encoder.inverse_transform(y_pred_num)[0]\n",
    "        \n",
    "        true_label = y.iloc[0]\n",
    "        \n",
    "        print(f\"\\nSample prediction:\")\n",
    "        print(f\"True genre: {true_label}\")\n",
    "        print(f\"Predicted genre: {prediction}\")\n",
    "        print(f\"Correct: {prediction == true_label}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Model file not found. Please run training first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # For Random Forest, we can get feature importance\n",
    "    try:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        \n",
    "        # Train a simple Random Forest for feature importance\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Get feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': rf.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Plot top 20 features\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = feature_importance.head(20)\n",
    "        plt.barh(range(len(top_features)), top_features['importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Top 20 Most Important Features')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_importance.head(10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing feature importance: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
